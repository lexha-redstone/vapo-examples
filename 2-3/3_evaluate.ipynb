{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d81eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.genai as genai\n",
    "import pandas as pd\n",
    "\n",
    "# PROJECT_ID = '$YOUR_PROJECT_ID'\n",
    "client = genai.Client(vertexai=False, api_key=\"$YOUR_GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ced5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c28a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_kr = pd.read_csv('./test-kr.csv')\n",
    "df_test_en = pd.read_csv('./test-en.csv')\n",
    "df_test_cmn = pd.read_csv('./test-cmn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e62ad2",
   "metadata": {},
   "source": [
    "### Test Korean STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bcfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_prompt = 'Generate a transcript of the speech. Only include the transcript in your response, and do not provide any other answer'\n",
    "initial_prompt_korean = '주어진 음성 파일을 텍스트로 변환하세요. 응답에는 다른 어떠한 내용도 추가하지 마십시오.'\n",
    "\n",
    "# exact_match\n",
    "optimized_prompt = '''음성 내용을 텍스트로 변환하세요. 다음 지침을 엄격히 준수하여 응답을 생성하십시오:\n",
    "1. 텍스트 변환 내용에는 어떠한 문장 부호(마침표, 쉼표 등)도 포함하지 마십시오.\n",
    "2. 숫자는 원본 음성에서 발음된 형태를 그대로 따르십시오. (예: '이백만'이 발음되면 '이백만'으로, '열여덟'이 발음되면 '열여덟'으로, '8명'이 발음되면 '8명'으로 표기)\n",
    "3. 어휘, 문장 구성, 그리고 단어 간 띄어쓰기는 원본 음성의 표현 방식을 최대한 충실하고 정확하게 따르십시오. 특히, 복합어의 띄어쓰기에 유의하십시오.\n",
    "응답에는 텍스트 변환 내용만 포함하고, 다른 답변은 제공하지 마세요.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4339b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_kr['initial_result'] = None\n",
    "df_test_kr['initial_korean_result'] = None\n",
    "df_test_kr['optimized_result'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3fb02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(df_test_kr)):\n",
    "    temp_wav_path = df_test_kr['audio'][idx]\n",
    "    myfile = client.files.upload(file=temp_wav_path)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=[initial_prompt, myfile]\n",
    "    )\n",
    "\n",
    "    df_test_kr.loc[idx, 'initial_result'] = response.text\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=[initial_prompt_korean, myfile]\n",
    "    )\n",
    "\n",
    "    df_test_kr.loc[idx, 'initial_korean_result'] = response.text\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=[optimized_prompt, myfile]\n",
    "    )\n",
    "\n",
    "    df_test_kr.loc[idx, 'optimized_result'] = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc729512",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['initial_result', 'initial_korean_result', 'optimized_result']\n",
    "\n",
    "for col in col_list:\n",
    "    wer_score = wer_metric.compute(predictions=df_test_kr[col], references=df_test_kr['target'])\n",
    "    cer_score = cer_metric.compute(predictions=df_test_kr[col], references=df_test_kr['target'])\n",
    "\n",
    "    print(f\"{col} WER : {wer_score:.4f}\")\n",
    "    print(f\"{col} CER : {cer_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):    \n",
    "    punctuations = string.punctuation\n",
    "    translator = str.maketrans('', '', punctuations)\n",
    "    \n",
    "    # 3. 테이블을 이용하여 텍스트 변환 및 반환\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "df_test_kr['initial_result_no_punc'] = df_test_kr['initial_result'].apply(lambda x: remove_punctuation(x))\n",
    "df_test_kr['initial_korean_result_no_punc'] = df_test_kr['initial_korean_result'].apply(lambda x: remove_punctuation(x))\n",
    "df_test_kr['optimized_result_no_punc'] = df_test_kr['optimized_result'].apply(lambda x: remove_punctuation(x))\n",
    "df_test_kr['target_no_punc'] = df_test_kr['target'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['initial_result_no_punc', 'initial_korean_result_no_punc' ,'optimized_result_no_punc']\n",
    "\n",
    "for col in col_list:\n",
    "    wer_score = wer_metric.compute(predictions=df_test_kr[col], references=df_test_kr['target_no_punc'])\n",
    "    cer_score = cer_metric.compute(predictions=df_test_kr[col], references=df_test_kr['target_no_punc'])\n",
    "\n",
    "    print(f\"{col} WER : {wer_score:.4f}\")\n",
    "    print(f\"{col} CER : {cer_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129cc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_kr['initial_wer'] = df_test_kr.apply(lambda x: wer_metric.compute(predictions=[x.initial_result_no_punc],references=[x.target_no_punc]) ,axis=1)\n",
    "# df_test_kr['initial_cer'] = df_test_kr.apply(lambda x: cer_metric.compute(predictions=[x.initial_result_no_punc],references=[x.target_no_punc]) ,axis=1)\n",
    "\n",
    "\n",
    "# df_test_kr['optimized_wer'] = df_test_kr.apply(lambda x: wer_metric.compute(predictions=[x.optimized_result_no_punc],references=[x.target_no_punc]) ,axis=1)\n",
    "# df_test_kr['optimized_cer'] = df_test_kr.apply(lambda x: cer_metric.compute(predictions=[x.optimized_result_no_punc],references=[x.target_no_punc]) ,axis=1)\n",
    "\n",
    "# print(f\"Optimized showed better WER : {df_test_kr[df_test_kr['initial_wer'] > df_test_kr['optimized_wer']].shape[0]}\")\n",
    "# print(f\"Initial showed better WER : {df_test_kr[df_test_kr['initial_wer'] < df_test_kr['optimized_wer']].shape[0]}\")\n",
    "# print(f\"Same WER : {df_test_kr[df_test_kr['initial_wer'] == df_test_kr['optimized_wer']].shape[0]}\")\n",
    "\n",
    "# print(f\"Optimized showed better CER : {df_test_kr[df_test_kr['initial_cer'] > df_test_kr['optimized_cer']].shape[0]}\")\n",
    "# print(f\"Initial showed better CER : {df_test_kr[df_test_kr['initial_cer'] < df_test_kr['optimized_cer']].shape[0]}\")\n",
    "# print(f\"Same CER : {df_test_kr[df_test_kr['initial_cer'] == df_test_kr['optimized_cer']].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_kr.sort_values(by='cer_diff', ascending=False)[:5]\n",
    "# df_test_kr.sort_values(by='wer_diff', ascending=False)[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e662c7",
   "metadata": {},
   "source": [
    "### Test English STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10654446",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_prompt_en = 'Generate a transcript of the speech. Only include the transcript in your response, and do not provide any other answer'\n",
    "optimized_prompt_en = \"Generate a transcript of the speech. The transcript must be in all lowercase. The transcript must precisely reflect the spoken content, transcribing only the exact words spoken without adding, omitting, or substituting any words. Strive for accurate phonetic transcription and correct spelling of all words. It is paramount to correctly identify and transcribe proper nouns, ensuring their exact and accurate spelling based on common or established forms, even when they sound phonetically similar to common phrases or words. Numerical values, including years, must be transcribed as digits (e.g., '1767', not 'seventeen sixty-seven'). Retain punctuation only when it is an intrinsic part of a word's spelling, such as apostrophes in contractions or hyphens in compound words, especially for compound adjectives that modify a noun (e.g., 'full-iron'). Omit all other punctuation. Only include the transcript in your response, and do not provide any other answer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_en['initial_result'] = None\n",
    "df_test_en['optimized_result'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe56bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(df_test_en)):\n",
    "    temp_wav_path = df_test_en['audio'][idx]\n",
    "    myfile = client.files.upload(file=temp_wav_path)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=[initial_prompt_en, myfile]\n",
    "    )\n",
    "\n",
    "    df_test_en.loc[idx, 'initial_result'] = response.text\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=[optimized_prompt_en, myfile]\n",
    "    )\n",
    "\n",
    "    df_test_en.loc[idx, 'optimized_result'] = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['initial_result', 'optimized_result']\n",
    "\n",
    "for col in col_list:\n",
    "    wer_score = wer_metric.compute(predictions=df_test_en[col], references=df_test_en['target'])\n",
    "    cer_score = cer_metric.compute(predictions=df_test_en[col], references=df_test_en['target'])\n",
    "\n",
    "    print(f\"{col} WER : {wer_score:.4f}\")\n",
    "    print(f\"{col} CER : {cer_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation & lowercasing\n",
    "df_test_en['initial_result_no_punc'] = df_test_en['initial_result'].apply(lambda x: remove_punctuation(x.lower()))\n",
    "df_test_en['optimized_result_no_punc'] = df_test_en['optimized_result'].apply(lambda x: remove_punctuation(x.lower()))\n",
    "df_test_en['target_no_punc'] = df_test_en['target'].apply(lambda x: remove_punctuation(x.lower()))\n",
    "\n",
    "col_list = ['initial_result_no_punc', 'optimized_result_no_punc']\n",
    "\n",
    "for col in col_list:\n",
    "    wer_score = wer_metric.compute(predictions=df_test_en[col], references=df_test_en['target_no_punc'])\n",
    "    cer_score = cer_metric.compute(predictions=df_test_en[col], references=df_test_en['target_no_punc'])\n",
    "\n",
    "    print(f\"{col} WER : {wer_score:.4f}\")\n",
    "    print(f\"{col} CER : {cer_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa88f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_en['initial_wer'] = df_test_en.apply(lambda x: wer_metric.compute(predictions=[x.initial_result_no_punc],references=[x.target_no_punc]) ,axis=1)\n",
    "# df_test_en['initial_cer'] = df_test_en.apply(lambda x: cer_metric.compute(predictions=[x.initial_result_no_punc],references=[x.target_no_punc]) ,axis=1)\n",
    "\n",
    "# df_test_en['optimized_wer'] = df_test_en.apply(lambda x: wer_metric.compute(predictions=[x.optimized_result_no_punc],references=[x.target_no_punc]) ,axis=1)\n",
    "# df_test_en['optimized_cer'] = df_test_en.apply(lambda x: cer_metric.compute(predictions=[x.optimized_result_no_punc],references=[x.target_no_punc]) ,axis=1)\n",
    "\n",
    "# df_test_en['wer_diff'] = df_test_en['initial_wer'] - df_test_en['optimized_wer']\n",
    "# df_test_en['cer_diff'] = df_test_en['initial_cer'] - df_test_en['optimized_cer']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d83b29",
   "metadata": {},
   "source": [
    "### Test Chinese (Mandarin) STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65edfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_prompt = 'Generate a transcript of the speech. Only include the transcript in your response, and do not provide any other answer. Please answer in Simplified Chinese.'\n",
    "initial_prompt_cmn = '生成演讲稿的文字记录。在您的回复中只包含文字记录，不要提供任何其他答案。请使用简体中文回答。'\n",
    "optimized_prompt_cmn = '请根据提供的音频标识符，生成对应的标准文本内容。转录文本应不包含任何标点符号。数字应优先使用阿拉伯数字（0-9）转录。但对于中文习惯中以汉字形式出现的数字（如序数词、量词或固定搭配），应保留其汉字形式。文本中，每个汉字之间（包括组成词语的汉字）都必须用一个空格隔开。您的回复中只包含符合此格式要求的转录文本，不要提供任何其他信息。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d078ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cmn['initial_result'] = None\n",
    "df_test_cmn['initial_mandarin_result'] = None\n",
    "df_test_cmn['optimized_result'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf90806",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(df_test_cmn)):\n",
    "    temp_wav_path = df_test_cmn['audio'][idx]\n",
    "    myfile = client.files.upload(file=temp_wav_path)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=[initial_prompt, myfile]\n",
    "    )\n",
    "\n",
    "    df_test_cmn.loc[idx, 'initial_result'] = response.text\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=[initial_prompt_cmn, myfile]\n",
    "    )\n",
    "\n",
    "    df_test_cmn.loc[idx, 'initial_mandarin_result'] = response.text\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=[optimized_prompt_cmn, myfile]\n",
    "    )\n",
    "\n",
    "    df_test_cmn.loc[idx, 'optimized_result'] = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0fd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['initial_result', 'initial_mandarin_result', 'optimized_result']\n",
    "\n",
    "for col in col_list:\n",
    "    wer_score = wer_metric.compute(predictions=df_test_cmn[col], references=df_test_cmn['target'])\n",
    "    cer_score = cer_metric.compute(predictions=df_test_cmn[col], references=df_test_cmn['target'])\n",
    "\n",
    "    print(f\"{col} WER : {wer_score:.4f}\")\n",
    "    print(f\"{col} CER : {cer_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cmn['target_nospace'] = df_test_cmn['target'].apply(lambda x: x.replace(' ', ''))\n",
    "df_test_cmn['initial_result_nospace'] = df_test_cmn['initial_result'].apply(lambda x: x.replace(' ', ''))\n",
    "df_test_cmn['initial_mandarin_result_nospace'] = df_test_cmn['initial_mandarin_result'].apply(lambda x: x.replace(' ', ''))\n",
    "df_test_cmn['optimized_result_nospace'] = df_test_cmn['optimized_result'].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['initial_result_nospace', 'initial_mandarin_result_nospace', 'optimized_result_nospace']\n",
    "\n",
    "for col in col_list:\n",
    "    cer_score = cer_metric.compute(predictions=df_test_cmn[col], references=df_test_cmn['target_nospace'])\n",
    "    print(f\"{col} CER : {cer_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation & remove whitespace\n",
    "df_test_cmn['initial_result_no_punc'] = df_test_cmn['initial_result_nospace'].apply(lambda x: remove_punctuation(x))\n",
    "df_test_cmn['initial_mandarin_result_no_punc'] = df_test_cmn['initial_mandarin_result_nospace'].apply(lambda x: remove_punctuation(x))\n",
    "df_test_cmn['optimized_result_no_punc'] = df_test_cmn['optimized_result_nospace'].apply(lambda x: remove_punctuation(x))\n",
    "df_test_cmn['target_no_punc'] = df_test_cmn['target_nospace'].apply(lambda x: remove_punctuation(x.lower()))\n",
    "\n",
    "col_list = ['initial_result_no_punc', 'initial_mandarin_result_no_punc', 'optimized_result_no_punc']\n",
    "\n",
    "for col in col_list:\n",
    "    cer_score = cer_metric.compute(predictions=df_test_cmn[col], references=df_test_cmn['target_no_punc'])\n",
    "    print(f\"{col} CER : {cer_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be619727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
