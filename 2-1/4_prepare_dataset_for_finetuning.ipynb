{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d55477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "886318cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sample_data/train_df_sampled_vapo.csv')\n",
    "valid = pd.read_csv('sample_data/test_df_sampled_vapo.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b150d408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>```json\\n{\\n  \"toxicity\":0.0,\\n  \"severe_toxic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With the rate of pedophilia in the LBGTQ commu...</td>\n",
       "      <td>```json\\n{\\n  \"toxicity\":0.3,\\n  \"severe_toxic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In addition, it's been 174 days and counting ....</td>\n",
       "      <td>```json\\n{\\n  \"toxicity\":0.0,\\n  \"severe_toxic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  This is so cool. It's like, 'would you want yo...   \n",
       "1  With the rate of pedophilia in the LBGTQ commu...   \n",
       "2  In addition, it's been 174 days and counting ....   \n",
       "\n",
       "                                            response  \n",
       "0  ```json\\n{\\n  \"toxicity\":0.0,\\n  \"severe_toxic...  \n",
       "1  ```json\\n{\\n  \"toxicity\":0.3,\\n  \"severe_toxic...  \n",
       "2  ```json\\n{\\n  \"toxicity\":0.0,\\n  \"severe_toxic...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f46034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_prompt_2 = '''Analyze the given \"text\" for toxicity across specific categories. Each score must be a float between 0.0 (indicating complete absence) and 1.0 (indicating extreme presence). Scores should be 0.0 if the text unequivocally does not contain any element of that specific toxicity category. Scores should reflect the degree to which the text contains direct, explicit, and harmful content. Strong negative opinions or criticisms are not considered toxic unless they involve direct personal attacks, hate speech, or explicit threats. **Category Definitions:** - **toxicity**: Language that is rude, disrespectful, or likely to make someone leave a discussion. This includes general unpleasantness but excludes strong, non-personal criticism. - **severe_toxicity**: Explicitly hateful, aggressive, or highly disrespectful comments. This category is for content that is severely offensive, includes direct threats, or incites violence. - **obscene**: Language containing profanity, vulgarity, or sexually suggestive content. - **threat**: Any statement explicitly expressing an intent to cause harm, injury, or damage to an individual or group. - **insult**: Direct personal attacks or demeaning language aimed at an individual or group. This does not include criticism of ideas or actions unless it becomes a personal attack. - **identity_attack**: Discriminatory or hateful language targeting an individual or group based on protected characteristics (e.g., race, gender, religion, sexual orientation). - **sexual_explicit**: Content with overt sexual references, descriptions, or imagery. Your response must be only a single, valid JSON object with the specified keys, formatted exactly as shown below. If the query contains examples, use them as a guide for scoring and output format, then provide the score for the final 'text' entry. Output format: ```json { \"toxicity\":, \"severe_toxicity\":, \"obscene\":, \"threat\":, \"insult\":, \"identity_attack\":, \"sexual_explicit\": } ``` Some examples of correct JSON Output are: text: Exactly -- if anyone found themselves in the situation of either Khadr or Speer, and they had low-risk avenues for serious civil damages wins, they would most likely use them. answer : ```json { \"toxicity\":0.0, \"severe_toxicity\":0.0, \"obscene\":0.0, \"threat\":0.0, \"insult\":0.0, \"identity_attack\":0.0, \"sexual_explicit\":0.0 } ``` == Some examples of correct JSON Output are: text: John F. Kennedy's acceptance by the public had much to do with two things: 1) WWII erased a great deal of America's bigotry toward Catholics, because during the war protestants served alongside Catholics and saw first hand that they weren't slaves of Rome. Before then, much of America was isolated into pockets of parochial believers, and so had relatively little contact with those of other sects. 2) JFK really did have unusual charisma, and people tend to make allowances for Alphas. answer : ```json { \"toxicity\":0.0, \"severe_toxicity\":0.0, \"obscene\":0.0, \"threat\":0.0, \"insult\":0.0, \"identity_attack\":0.0, \"sexual_explicit\":0.0 } ``` == Some examples of correct JSON Output are: text: Thanks to the Greenbelt. Supply is artificially restricted, allowing the prices to skyrocket. 15-20% average annual return is guaranteed. answer : ```json { \"toxicity\":0.0, \"severe_toxicity\":0.0, \"obscene\":0.0, \"threat\":0.0, \"insult\":0.0, \"identity_attack\":0.0, \"sexual_explicit\":0.0 } ```'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7a66aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsonl_entry(row):    \n",
    "    system_part = {\n",
    "        \"role\": \"system\",\n",
    "        \"parts\": [\n",
    "            {\"text\": optimized_prompt_2}\n",
    "        ]\n",
    "    }\n",
    "    contents_part = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [\n",
    "                {\"text\": row['text']}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"model\",\n",
    "            \"parts\": [\n",
    "                {\"text\": row['response']}\n",
    "            ]\n",
    "        }\n",
    "    ]    \n",
    "    entry = {\n",
    "        \"systemInstruction\": system_part,\n",
    "        \"contents\": contents_part\n",
    "    }\n",
    "    \n",
    "    return entry\n",
    "\n",
    "json_series = train.apply(create_jsonl_entry, axis=1)\n",
    "valid_json_series = valid.apply(create_jsonl_entry, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "030e26a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sample_data/train_tuning_data.jsonl' created.\n",
      "--- File format (Top 2 lines) ---\n",
      "{\"systemInstruction\": {\"role\": \"system\", \"parts\": [{\"text\": \"Analyze the given \\\"text\\\" for toxicity across specific categories. Each score must be a float between 0.0 (indicating complete absence) and 1.0 (indicating extreme presence). Scores should be 0.0 if the text unequivocally does not contain any element of that specific toxicity category. Scores should reflect the degree to which the text contains direct, explicit, and harmful content. Strong negative opinions or criticisms are not considered toxic unless they involve direct personal attacks, hate speech, or explicit threats. **Category Definitions:** - **toxicity**: Language that is rude, disrespectful, or likely to make someone leave a discussion. This includes general unpleasantness but excludes strong, non-personal criticism. - **severe_toxicity**: Explicitly hateful, aggressive, or highly disrespectful comments. This category is for content that is severely offensive, includes direct threats, or incites violence. - **obscene**: Language containing profanity, vulgarity, or sexually suggestive content. - **threat**: Any statement explicitly expressing an intent to cause harm, injury, or damage to an individual or group. - **insult**: Direct personal attacks or demeaning language aimed at an individual or group. This does not include criticism of ideas or actions unless it becomes a personal attack. - **identity_attack**: Discriminatory or hateful language targeting an individual or group based on protected characteristics (e.g., race, gender, religion, sexual orientation). - **sexual_explicit**: Content with overt sexual references, descriptions, or imagery. Your response must be only a single, valid JSON object with the specified keys, formatted exactly as shown below. If the query contains examples, use them as a guide for scoring and output format, then provide the score for the final 'text' entry. Output format: ```json { \\\"toxicity\\\":, \\\"severe_toxicity\\\":, \\\"obscene\\\":, \\\"threat\\\":, \\\"insult\\\":, \\\"identity_attack\\\":, \\\"sexual_explicit\\\": } ``` Some examples of correct JSON Output are: text: Exactly -- if anyone found themselves in the situation of either Khadr or Speer, and they had low-risk avenues for serious civil damages wins, they would most likely use them. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ``` == Some examples of correct JSON Output are: text: John F. Kennedy's acceptance by the public had much to do with two things: 1) WWII erased a great deal of America's bigotry toward Catholics, because during the war protestants served alongside Catholics and saw first hand that they weren't slaves of Rome. Before then, much of America was isolated into pockets of parochial believers, and so had relatively little contact with those of other sects. 2) JFK really did have unusual charisma, and people tend to make allowances for Alphas. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ``` == Some examples of correct JSON Output are: text: Thanks to the Greenbelt. Supply is artificially restricted, allowing the prices to skyrocket. 15-20% average annual return is guaranteed. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ```\"}]}, \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\"}]}, {\"role\": \"model\", \"parts\": [{\"text\": \"```json\\n{\\n  \\\"toxicity\\\":0.0,\\n  \\\"severe_toxicity\\\":0.0,\\n  \\\"obscene\\\":0.0,\\n  \\\"threat\\\":0.0,\\n  \\\"insult\\\":0.0,\\n  \\\"identity_attack\\\":0.0,\\n  \\\"sexual_explicit\\\":0.0\\n}\\n```\"}]}]}\n",
      "{\"systemInstruction\": {\"role\": \"system\", \"parts\": [{\"text\": \"Analyze the given \\\"text\\\" for toxicity across specific categories. Each score must be a float between 0.0 (indicating complete absence) and 1.0 (indicating extreme presence). Scores should be 0.0 if the text unequivocally does not contain any element of that specific toxicity category. Scores should reflect the degree to which the text contains direct, explicit, and harmful content. Strong negative opinions or criticisms are not considered toxic unless they involve direct personal attacks, hate speech, or explicit threats. **Category Definitions:** - **toxicity**: Language that is rude, disrespectful, or likely to make someone leave a discussion. This includes general unpleasantness but excludes strong, non-personal criticism. - **severe_toxicity**: Explicitly hateful, aggressive, or highly disrespectful comments. This category is for content that is severely offensive, includes direct threats, or incites violence. - **obscene**: Language containing profanity, vulgarity, or sexually suggestive content. - **threat**: Any statement explicitly expressing an intent to cause harm, injury, or damage to an individual or group. - **insult**: Direct personal attacks or demeaning language aimed at an individual or group. This does not include criticism of ideas or actions unless it becomes a personal attack. - **identity_attack**: Discriminatory or hateful language targeting an individual or group based on protected characteristics (e.g., race, gender, religion, sexual orientation). - **sexual_explicit**: Content with overt sexual references, descriptions, or imagery. Your response must be only a single, valid JSON object with the specified keys, formatted exactly as shown below. If the query contains examples, use them as a guide for scoring and output format, then provide the score for the final 'text' entry. Output format: ```json { \\\"toxicity\\\":, \\\"severe_toxicity\\\":, \\\"obscene\\\":, \\\"threat\\\":, \\\"insult\\\":, \\\"identity_attack\\\":, \\\"sexual_explicit\\\": } ``` Some examples of correct JSON Output are: text: Exactly -- if anyone found themselves in the situation of either Khadr or Speer, and they had low-risk avenues for serious civil damages wins, they would most likely use them. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ``` == Some examples of correct JSON Output are: text: John F. Kennedy's acceptance by the public had much to do with two things: 1) WWII erased a great deal of America's bigotry toward Catholics, because during the war protestants served alongside Catholics and saw first hand that they weren't slaves of Rome. Before then, much of America was isolated into pockets of parochial believers, and so had relatively little contact with those of other sects. 2) JFK really did have unusual charisma, and people tend to make allowances for Alphas. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ``` == Some examples of correct JSON Output are: text: Thanks to the Greenbelt. Supply is artificially restricted, allowing the prices to skyrocket. 15-20% average annual return is guaranteed. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ```\"}]}, \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"With the rate of pedophilia in the LBGTQ community being eleven to one, at least now the kids can sue the government when they are abused in Boy Scouts, daycares or school by one of the members of the LBGTQ community.\\n\\n\\\"The proportions of heterosexual and homosexual pedophiles among sex offenders against children: an exploratory study.\\\"\\n\\\"the ratio of homosexual﻿ to heterosexual pedophiles was calculated to be 11:1.\\\"\"}]}, {\"role\": \"model\", \"parts\": [{\"text\": \"```json\\n{\\n  \\\"toxicity\\\":0.3,\\n  \\\"severe_toxicity\\\":0.0,\\n  \\\"obscene\\\":0.0,\\n  \\\"threat\\\":0.0,\\n  \\\"insult\\\":0.0,\\n  \\\"identity_attack\\\":0.3,\\n  \\\"sexual_explicit\\\":0.2\\n}\\n```\"}]}]}\n"
     ]
    }
   ],
   "source": [
    "output_filename = 'sample_data/train_tuning_data.jsonl'\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    for entry_dict in json_series:\n",
    "        # json.dumps : Python 딕셔너리를 JSON 문자열로 변환\n",
    "        # ensure_ascii=False : 한글이 깨지지 않도록 처리\n",
    "        f.write(json.dumps(entry_dict, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"'{output_filename}' created.\")\n",
    "print(\"--- File format (Top 2 lines) ---\")\n",
    "with open(output_filename, 'r', encoding='utf-8') as f:\n",
    "    print(f.readline(), end=\"\")\n",
    "    print(f.readline(), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc11e758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sample_data/valid_tuning_data.jsonl' created.\n",
      "--- File format (Top 2 lines) ---\n",
      "{\"systemInstruction\": {\"role\": \"system\", \"parts\": [{\"text\": \"Analyze the given \\\"text\\\" for toxicity across specific categories. Each score must be a float between 0.0 (indicating complete absence) and 1.0 (indicating extreme presence). Scores should be 0.0 if the text unequivocally does not contain any element of that specific toxicity category. Scores should reflect the degree to which the text contains direct, explicit, and harmful content. Strong negative opinions or criticisms are not considered toxic unless they involve direct personal attacks, hate speech, or explicit threats. **Category Definitions:** - **toxicity**: Language that is rude, disrespectful, or likely to make someone leave a discussion. This includes general unpleasantness but excludes strong, non-personal criticism. - **severe_toxicity**: Explicitly hateful, aggressive, or highly disrespectful comments. This category is for content that is severely offensive, includes direct threats, or incites violence. - **obscene**: Language containing profanity, vulgarity, or sexually suggestive content. - **threat**: Any statement explicitly expressing an intent to cause harm, injury, or damage to an individual or group. - **insult**: Direct personal attacks or demeaning language aimed at an individual or group. This does not include criticism of ideas or actions unless it becomes a personal attack. - **identity_attack**: Discriminatory or hateful language targeting an individual or group based on protected characteristics (e.g., race, gender, religion, sexual orientation). - **sexual_explicit**: Content with overt sexual references, descriptions, or imagery. Your response must be only a single, valid JSON object with the specified keys, formatted exactly as shown below. If the query contains examples, use them as a guide for scoring and output format, then provide the score for the final 'text' entry. Output format: ```json { \\\"toxicity\\\":, \\\"severe_toxicity\\\":, \\\"obscene\\\":, \\\"threat\\\":, \\\"insult\\\":, \\\"identity_attack\\\":, \\\"sexual_explicit\\\": } ``` Some examples of correct JSON Output are: text: Exactly -- if anyone found themselves in the situation of either Khadr or Speer, and they had low-risk avenues for serious civil damages wins, they would most likely use them. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ``` == Some examples of correct JSON Output are: text: John F. Kennedy's acceptance by the public had much to do with two things: 1) WWII erased a great deal of America's bigotry toward Catholics, because during the war protestants served alongside Catholics and saw first hand that they weren't slaves of Rome. Before then, much of America was isolated into pockets of parochial believers, and so had relatively little contact with those of other sects. 2) JFK really did have unusual charisma, and people tend to make allowances for Alphas. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ``` == Some examples of correct JSON Output are: text: Thanks to the Greenbelt. Supply is artificially restricted, allowing the prices to skyrocket. 15-20% average annual return is guaranteed. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ```\"}]}, \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"[ Integrity means that you pay your debts.]\\n\\nDoes this apply to President Trump too?\"}]}, {\"role\": \"model\", \"parts\": [{\"text\": \"```json\\n{\\n  \\\"toxicity\\\":0.0,\\n  \\\"severe_toxicity\\\":0.0,\\n  \\\"obscene\\\":0.0,\\n  \\\"threat\\\":0.0,\\n  \\\"insult\\\":0.0,\\n  \\\"identity_attack\\\":0.0,\\n  \\\"sexual_explicit\\\":0.0\\n}\\n```\"}]}]}\n",
      "{\"systemInstruction\": {\"role\": \"system\", \"parts\": [{\"text\": \"Analyze the given \\\"text\\\" for toxicity across specific categories. Each score must be a float between 0.0 (indicating complete absence) and 1.0 (indicating extreme presence). Scores should be 0.0 if the text unequivocally does not contain any element of that specific toxicity category. Scores should reflect the degree to which the text contains direct, explicit, and harmful content. Strong negative opinions or criticisms are not considered toxic unless they involve direct personal attacks, hate speech, or explicit threats. **Category Definitions:** - **toxicity**: Language that is rude, disrespectful, or likely to make someone leave a discussion. This includes general unpleasantness but excludes strong, non-personal criticism. - **severe_toxicity**: Explicitly hateful, aggressive, or highly disrespectful comments. This category is for content that is severely offensive, includes direct threats, or incites violence. - **obscene**: Language containing profanity, vulgarity, or sexually suggestive content. - **threat**: Any statement explicitly expressing an intent to cause harm, injury, or damage to an individual or group. - **insult**: Direct personal attacks or demeaning language aimed at an individual or group. This does not include criticism of ideas or actions unless it becomes a personal attack. - **identity_attack**: Discriminatory or hateful language targeting an individual or group based on protected characteristics (e.g., race, gender, religion, sexual orientation). - **sexual_explicit**: Content with overt sexual references, descriptions, or imagery. Your response must be only a single, valid JSON object with the specified keys, formatted exactly as shown below. If the query contains examples, use them as a guide for scoring and output format, then provide the score for the final 'text' entry. Output format: ```json { \\\"toxicity\\\":, \\\"severe_toxicity\\\":, \\\"obscene\\\":, \\\"threat\\\":, \\\"insult\\\":, \\\"identity_attack\\\":, \\\"sexual_explicit\\\": } ``` Some examples of correct JSON Output are: text: Exactly -- if anyone found themselves in the situation of either Khadr or Speer, and they had low-risk avenues for serious civil damages wins, they would most likely use them. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ``` == Some examples of correct JSON Output are: text: John F. Kennedy's acceptance by the public had much to do with two things: 1) WWII erased a great deal of America's bigotry toward Catholics, because during the war protestants served alongside Catholics and saw first hand that they weren't slaves of Rome. Before then, much of America was isolated into pockets of parochial believers, and so had relatively little contact with those of other sects. 2) JFK really did have unusual charisma, and people tend to make allowances for Alphas. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ``` == Some examples of correct JSON Output are: text: Thanks to the Greenbelt. Supply is artificially restricted, allowing the prices to skyrocket. 15-20% average annual return is guaranteed. answer : ```json { \\\"toxicity\\\":0.0, \\\"severe_toxicity\\\":0.0, \\\"obscene\\\":0.0, \\\"threat\\\":0.0, \\\"insult\\\":0.0, \\\"identity_attack\\\":0.0, \\\"sexual_explicit\\\":0.0 } ```\"}]}, \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"Perhaps this is just Karma coming back to bite those people who voted for Justin without understanding what uncontrolled government spending really means. \\n\\nYes I do believe that most millennials voted for Justin.\"}]}, {\"role\": \"model\", \"parts\": [{\"text\": \"```json\\n{\\n  \\\"toxicity\\\":0.0,\\n  \\\"severe_toxicity\\\":0.0,\\n  \\\"obscene\\\":0.0,\\n  \\\"threat\\\":0.0,\\n  \\\"insult\\\":0.0,\\n  \\\"identity_attack\\\":0.0,\\n  \\\"sexual_explicit\\\":0.0\\n}\\n```\"}]}]}\n"
     ]
    }
   ],
   "source": [
    "output_filename = 'sample_data/valid_tuning_data.jsonl'\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    for entry_dict in valid_json_series:\n",
    "        # json.dumps : Python 딕셔너리를 JSON 문자열로 변환\n",
    "        # ensure_ascii=False : 한글이 깨지지 않도록 처리\n",
    "        f.write(json.dumps(entry_dict, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"'{output_filename}' created.\")\n",
    "print(\"--- File format (Top 2 lines) ---\")\n",
    "with open(output_filename, 'r', encoding='utf-8') as f:\n",
    "    print(f.readline(), end=\"\")\n",
    "    print(f.readline(), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dcba44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
